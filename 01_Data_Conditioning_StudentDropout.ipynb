{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBYQvg3Wtgpeq24hqFd/0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithuuu13/ANN-StudentDropout/blob/main/01_Data_Conditioning_StudentDropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Conditioning: Acquisition, Exploration, Cleaning, Encoding & Splitting\n",
        "\n",
        "This section performs the Data Conditioning phase of the Machine Learning Pipeline.\n",
        "\n",
        "Neural Networks require:\n",
        "\n",
        "\n",
        "*   clean and consistent input patterns\n",
        "*   numerical inputs\n",
        "*   scaled features for stable gradient descent\n",
        "*   training/validation/testing separation\n",
        "\n",
        "This section prepares the UCI Predict Students Dropout and Academic Success dataset so it can be used as valid input to a Multilayer Perceptron (MLP) trained via backpropagation."
      ],
      "metadata": {
        "id": "6lD66bAddhAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ],
      "metadata": {
        "id": "MAHo1k_6egti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n",
        "\n",
        "The dataset is obtained from the UCI Machine Learning Repository, fulfilling the “real-world data” criterion. This is also a supervised multi-class classification problem.\n",
        "\n",
        "It contains demographic, academic, and socioeconomic features used to predict whether a student will:\n",
        "\n",
        "*   Dropout\n",
        "*   Enrol\n",
        "*   Graduate\n",
        "\n"
      ],
      "metadata": {
        "id": "zpHbztlSeqEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J40bYdAefZQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/static/public/697/data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "chHA0G4gfT-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "Networks learn from input patters, so before data can be used, it is important to:\n",
        "\n",
        "\n",
        "*   understand feature types\n",
        "*   inspect distributions\n",
        "*   check for noise and inconsistencies\n",
        "*   analyse target class balance\n",
        "*   analyse relationships between features\n",
        "\n",
        "\n",
        "This ensures the MLP receives well-understood, meaningful inputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "0wsa_wqZfnqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "VMARgXglgRAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "kkHtZ1ZugTUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=df['Target'])\n",
        "plt.title('Distribution of Student Outcomes')\n",
        "plt.show()\n",
        "\n",
        "df['Target'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "yBweBVwrgWYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Correlation Analysis\n",
        "\n",
        "Although the ANN does not require feature selection, correlation analysis provides insight into which numeric inputs may influence the output. This strengthens the EDA component."
      ],
      "metadata": {
        "id": "FzHK5JvJgZsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# encoding target temporarily to compute correlation\n",
        "target_encoded = df['Target'].astype('category').cat.codes\n",
        "\n",
        "correlation = df[numeric_cols].corrwith(target_encoded)\n",
        "correlation.sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "xuanYloLgtEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "\n",
        "Neural networks learn best when the data they are given is clean and consistent. Problems like missing values, repeated entries, or categories that are not labelled the same way can confuse the model and slow down learning. When the data is well-prepared, the training process tends to be smoother and more reliable.\n",
        "\n",
        "To keep things in good shape, we make sure to:\n",
        "*   Remove missing values\n",
        "*   Get rid of duplicate rows\n",
        "*   Standardise column names\n",
        "*   Check that categories are used consistently\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xjMpKE3hDCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for missing values\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "i9EDma8Khw-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "DBLL67aKh1Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Encoding\n",
        "\n",
        "The MLP computes weighted sums of inputs:\n",
        "\n",
        "∑ᵢ (wᵢ · xᵢ)\n",
        "\n",
        "Therefore, categorical inputs cannot be used directly because the perceptron cannot multiply a weight by a string. Due to the importance of numerical input patterns to consider, one-hot encoding is used which:\n",
        "*   converts categories → binary vectors\n",
        "*   avoids implying any ordinal relationship\n",
        "*   produces clean numerical inputs for ANN training\n"
      ],
      "metadata": {
        "id": "6gUQwdiGh3kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "id": "oV8slhmgijX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting\n",
        "A typical dataset split ensures that the model has enough data to learn while still providing separate sets to monitor performance.\n",
        "The training set should be the largest, the validation set is used to track overfitting during training, and the test set provides an unbiased measure of how well the model generalises.\n",
        "\n",
        "In this case, we use:\n",
        "*   70% training\n",
        "*   15% validation\n",
        "*   15% testing\n",
        "\n",
        "This keeps the validation and test sets in similar proportions, which helps maintain a balanced evaluation."
      ],
      "metadata": {
        "id": "ifklO13Gipib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded.drop(columns=['Target_Dropout', 'Target_Enrolled', 'Target_Graduate'], errors='ignore')\n",
        "y = df['Target']\n",
        "\n",
        "# first split: training (70%) + temp (30%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# second split: validation (15%) + testing (15%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "2-m-k-C5jrCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling (Standardization)\n",
        "\n",
        "This step is important for getting stable, reliable performance from an ANN.\n",
        "Because neural networks rely on gradient descent, the scale of the input features matters: very large values can cause unstable updates, while very small values can slow learning down.\n",
        "\n",
        "Standardizing the data helps by ensuring:\n",
        "* mean = 0\n",
        "* standard deviation = 1\n",
        "* faster convergence\n",
        "* more stable backpropagation\n",
        "\n",
        "The scaler is fitted only on the training data to prevent data leakage."
      ],
      "metadata": {
        "id": "cQmnQpo-jytM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# saving scaler for chetan rao sonoo ***********\n",
        "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))\n"
      ],
      "metadata": {
        "id": "h6CQz2imkHa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Processed Files\n",
        "\n",
        "These files will be used by the model development stage handled by the other teammate.\n",
        "\n",
        "We save:\n",
        "* Cleaned + encoded dataset\n",
        "* Scaler object (for consistent prediction inputs)"
      ],
      "metadata": {
        "id": "a04PJ_y1kdfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.to_csv(\"cleaned_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "KstDCF5JksRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}